{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b420cbf",
   "metadata": {},
   "source": [
    "# Review Radar - FastAPI Backend "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063bebb",
   "metadata": {},
   "source": [
    "## 1. Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50749e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All imports successful!\n",
      " PyTorch CUDA available: True\n",
      " PyTorch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# Core FastAPI and web framework imports\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import uvicorn\n",
    "\n",
    "# Machine Learning and NLP imports\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Utility imports\n",
    "import logging\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\" All imports successful!\")\n",
    "print(f\" PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\" PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0bc01",
   "metadata": {},
   "source": [
    "## 2. Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857966d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 18:39:05,060 - __main__ - INFO -  Logging configured successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger ready for use\n"
     ]
    }
   ],
   "source": [
    "# Configure logging for better debugging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Test logging\n",
    "logger.info(\" Logging configured successfully!\")\n",
    "print(\"Logger ready for use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d5d5e",
   "metadata": {},
   "source": [
    "## 3. Data Models (Pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900c9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pydantic models created successfully!\n",
      " Test request: {'reviews': ['Great product!', 'Not good at all']}\n"
     ]
    }
   ],
   "source": [
    "# Pydantic models for request/response validation\n",
    "\n",
    "class ReviewAnalysisRequest(BaseModel):\n",
    "    \"\"\"Request model for sentiment analysis\"\"\"\n",
    "    reviews: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"List of review texts to analyze\", \n",
    "        min_items=1,\n",
    "        example=[\"This product is amazing!\", \"Terrible quality, very disappointed\"]\n",
    "    )\n",
    "\n",
    "class ReviewSentiment(BaseModel):\n",
    "    \"\"\"Individual review sentiment result\"\"\"\n",
    "    review: str\n",
    "    sentiment: str\n",
    "    confidence: float\n",
    "\n",
    "class AnalysisResponse(BaseModel):\n",
    "    \"\"\"Complete analysis response with summary\"\"\"\n",
    "    results: List[ReviewSentiment]\n",
    "    summary: Dict[str, int]\n",
    "    total_reviews: int\n",
    "    processing_time_ms: float = 0.0\n",
    "\n",
    "# Test the models\n",
    "test_request = ReviewAnalysisRequest(reviews=[\"Great product!\", \"Not good at all\"])\n",
    "print(\" Pydantic models created successfully!\")\n",
    "print(f\" Test request: {test_request.model_dump()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb83776",
   "metadata": {},
   "source": [
    "## 4. Initialize Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce52a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 18:39:05,083 - __main__ - INFO - ü§ñ Loading sentiment analysis model...\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "2025-09-27 18:39:06,314 - __main__ - INFO -  Model loaded successfully! Using device: GPU (CUDA)\n",
      "2025-09-27 18:39:06,314 - __main__ - INFO -  Model loaded successfully! Using device: GPU (CUDA)\n",
      "2025-09-27 18:39:06,355 - __main__ - INFO -  Model test successful: [[{'label': 'NEGATIVE', 'score': 0.00012437114492058754}, {'label': 'POSITIVE', 'score': 0.9998756647109985}]]\n",
      "2025-09-27 18:39:06,355 - __main__ - INFO -  Model test successful: [[{'label': 'NEGATIVE', 'score': 0.00012437114492058754}, {'label': 'POSITIVE', 'score': 0.9998756647109985}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model initialization: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Global sentiment analyzer (will be initialized once)\n",
    "sentiment_analyzer = None\n",
    "\n",
    "def initialize_sentiment_model():\n",
    "    \"\"\"\n",
    "    Initialize the sentiment analysis model on startup\n",
    "    Using DistilBERT fine-tuned on Stanford Sentiment Treebank (SST-2)\n",
    "    \"\"\"\n",
    "    global sentiment_analyzer\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"ü§ñ Loading sentiment analysis model...\")\n",
    "        \n",
    "        # Load the specific model requested\n",
    "        model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        \n",
    "        # Initialize the pipeline with the model\n",
    "        sentiment_analyzer = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=model_name,\n",
    "            tokenizer=model_name,\n",
    "            return_all_scores=True,  # Get confidence scores\n",
    "            device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "        )\n",
    "        \n",
    "        device_info = 'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'\n",
    "        logger.info(f\" Model loaded successfully! Using device: {device_info}\")\n",
    "        \n",
    "        # Test the model with a sample text\n",
    "        test_result = sentiment_analyzer(\"This is a great product!\")\n",
    "        logger.info(f\" Model test successful: {test_result}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\" Failed to load sentiment model: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Initialize the model\n",
    "success = initialize_sentiment_model()\n",
    "print(f\" Model initialization: {'SUCCESS' if success else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ced4a0",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960133f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def map_sentiment_label(label: str) -> str:\n",
    "    \"\"\"\n",
    "    Map model output labels to standardized sentiment labels\n",
    "    DistilBERT SST-2 outputs: POSITIVE, NEGATIVE\n",
    "    We map to: Positive, Negative, Neutral (though SST-2 doesn't have neutral)\n",
    "    \"\"\"\n",
    "    label_mapping = {\n",
    "        \"POSITIVE\": \"Positive\",\n",
    "        \"NEGATIVE\": \"Negative\",\n",
    "        \"NEUTRAL\": \"Neutral\"  # For future models that support neutral\n",
    "    }\n",
    "    return label_mapping.get(label.upper(), label)\n",
    "\n",
    "def analyze_reviews_batch(reviews: List[str]) -> List[ReviewSentiment]:\n",
    "    \"\"\"\n",
    "    Analyze sentiment for a batch of reviews\n",
    "    Returns structured results with confidence scores\n",
    "    \"\"\"\n",
    "    if not sentiment_analyzer:\n",
    "        raise Exception(\"Sentiment model not initialized\")\n",
    "    \n",
    "    try:\n",
    "        # Process all reviews in batch for efficiency\n",
    "        logger.info(f\"üîç Analyzing {len(reviews)} reviews...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Get predictions for all reviews\n",
    "        predictions = sentiment_analyzer(reviews)\n",
    "        \n",
    "        results = []\n",
    "        for i, (review, prediction) in enumerate(zip(reviews, predictions)):\n",
    "            # Get the highest confidence prediction\n",
    "            best_prediction = max(prediction, key=lambda x: x['score'])\n",
    "            \n",
    "            sentiment = map_sentiment_label(best_prediction['label'])\n",
    "            confidence = round(best_prediction['score'], 4)\n",
    "            \n",
    "            results.append(ReviewSentiment(\n",
    "                review=review,\n",
    "                sentiment=sentiment,\n",
    "                confidence=confidence\n",
    "            ))\n",
    "            \n",
    "            logger.debug(f\" Review {i+1}: {sentiment} (confidence: {confidence})\")\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        logger.info(f\" Processing completed in {processing_time:.2f}ms\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\" Error during sentiment analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def calculate_summary(results: List[ReviewSentiment]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Calculate aggregate counts of sentiment labels\n",
    "    \"\"\"\n",
    "    summary = {\"Positive\": 0, \"Negative\": 0, \"Neutral\": 0}\n",
    "    \n",
    "    for result in results:\n",
    "        if result.sentiment in summary:\n",
    "            summary[result.sentiment] += 1\n",
    "    \n",
    "    return summary\n",
    "\n",
    "print(\" Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd541a3f",
   "metadata": {},
   "source": [
    "## 6. Test Individual Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c78cfbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 18:39:06,892 - __main__ - INFO - üîç Analyzing 5 reviews...\n",
      "2025-09-27 18:39:06,912 - __main__ - INFO -  Processing completed in 19.10ms\n",
      "2025-09-27 18:39:06,912 - __main__ - INFO -  Processing completed in 19.10ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing sentiment analysis with sample reviews...\n",
      "============================================================\n",
      "1. Review: This product is absolutely amazing! Best purchase ...\n",
      "   Sentiment: Positive (Confidence: 0.9999)\n",
      "\n",
      "2. Review: Terrible quality, broke after one day. Very disapp...\n",
      "   Sentiment: Negative (Confidence: 0.9997)\n",
      "\n",
      "3. Review: It's okay, nothing special but does the job....\n",
      "   Sentiment: Positive (Confidence: 0.9995)\n",
      "\n",
      "4. Review: Love it! Highly recommend to everyone!...\n",
      "   Sentiment: Positive (Confidence: 0.9999)\n",
      "\n",
      "5. Review: Worst product I've ever bought. Complete waste of ...\n",
      "   Sentiment: Negative (Confidence: 0.9998)\n",
      "\n",
      " Summary:\n",
      "   Positive: 3\n",
      "   Negative: 2\n",
      "   Neutral: 0\n",
      "\n",
      " Successfully analyzed 5 reviews!\n"
     ]
    }
   ],
   "source": [
    "# Test the sentiment analysis with sample reviews\n",
    "test_reviews = [\n",
    "    \"This product is absolutely amazing! Best purchase ever!\",\n",
    "    \"Terrible quality, broke after one day. Very disappointed.\",\n",
    "    \"It's okay, nothing special but does the job.\",\n",
    "    \"Love it! Highly recommend to everyone!\",\n",
    "    \"Worst product I've ever bought. Complete waste of money.\"\n",
    "]\n",
    "\n",
    "print(\" Testing sentiment analysis with sample reviews...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Analyze the test reviews\n",
    "    results = analyze_reviews_batch(test_reviews)\n",
    "    \n",
    "    # Display results\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. Review: {result.review[:50]}...\")\n",
    "        print(f\"   Sentiment: {result.sentiment} (Confidence: {result.confidence})\")\n",
    "        print()\n",
    "    \n",
    "    # Calculate and display summary\n",
    "    summary = calculate_summary(results)\n",
    "    print(\" Summary:\")\n",
    "    for sentiment, count in summary.items():\n",
    "        print(f\"   {sentiment}: {count}\")\n",
    "    \n",
    "    print(f\"\\n Successfully analyzed {len(results)} reviews!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error during testing: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
