{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b420cbf",
   "metadata": {},
   "source": [
    "# Review Radar - FastAPI Backend "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063bebb",
   "metadata": {},
   "source": [
    "## 1. Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50749e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch CUDA available: True\n",
      "PyTorch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# Core FastAPI and web framework imports\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import uvicorn\n",
    "\n",
    "# Machine Learning and NLP imports\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Utility imports\n",
    "import logging\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0bc01",
   "metadata": {},
   "source": [
    "## 2. Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "857966d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 20:59:26,710 - __main__ - INFO - Logging configured successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger ready for use\n"
     ]
    }
   ],
   "source": [
    "# Configure logging for better debugging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Test logging\n",
    "logger.info(\"Logging configured successfully!\")\n",
    "print(\"Logger ready for use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d5d5e",
   "metadata": {},
   "source": [
    "## 3. Data Models (Pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900c9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydantic models created successfully!\n",
      "Test request: {'reviews': ['Great product!', 'Not good at all']}\n"
     ]
    }
   ],
   "source": [
    "# Pydantic models for request/response validation\n",
    "\n",
    "class ReviewAnalysisRequest(BaseModel):\n",
    "    \"\"\"Request model for sentiment analysis\"\"\"\n",
    "    reviews: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"List of review texts to analyze\", \n",
    "        min_items=1,\n",
    "        example=[\"This product is amazing!\", \"Terrible quality, very disappointed\"]\n",
    "    )\n",
    "\n",
    "class ReviewSentiment(BaseModel):\n",
    "    \"\"\"Individual review sentiment result\"\"\"\n",
    "    review: str\n",
    "    sentiment: str\n",
    "    confidence: float\n",
    "\n",
    "class AnalysisResponse(BaseModel):\n",
    "    \"\"\"Complete analysis response with summary\"\"\"\n",
    "    results: List[ReviewSentiment]\n",
    "    summary: Dict[str, int]\n",
    "    total_reviews: int\n",
    "    processing_time_ms: float = 0.0\n",
    "\n",
    "# Test the models\n",
    "test_request = ReviewAnalysisRequest(reviews=[\"Great product!\", \"Not good at all\"])\n",
    "print(\"Pydantic models created successfully!\")\n",
    "print(f\"Test request: {test_request.model_dump()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb83776",
   "metadata": {},
   "source": [
    "## 4. Initialize Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce52a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 20:59:26,735 - __main__ - INFO - Loading sentiment analysis model...\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "2025-09-27 20:59:28,785 - __main__ - INFO - Model loaded successfully! Using device: GPU (CUDA)\n",
      "2025-09-27 20:59:28,785 - __main__ - INFO - Model loaded successfully! Using device: GPU (CUDA)\n",
      "2025-09-27 20:59:28,816 - __main__ - INFO - Model test successful: [[{'label': 'NEGATIVE', 'score': 0.00012437114492058754}, {'label': 'POSITIVE', 'score': 0.9998756647109985}]]\n",
      "2025-09-27 20:59:28,816 - __main__ - INFO - Model test successful: [[{'label': 'NEGATIVE', 'score': 0.00012437114492058754}, {'label': 'POSITIVE', 'score': 0.9998756647109985}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialization: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Global sentiment analyzer (will be initialized once)\n",
    "sentiment_analyzer = None\n",
    "\n",
    "def initialize_sentiment_model():\n",
    "    \"\"\"\n",
    "    Initialize the sentiment analysis model on startup\n",
    "    Using DistilBERT fine-tuned on Stanford Sentiment Treebank (SST-2)\n",
    "    \"\"\"\n",
    "    global sentiment_analyzer\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Loading sentiment analysis model...\")\n",
    "        \n",
    "        # Load the specific model requested\n",
    "        model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        \n",
    "        # Initialize the pipeline with the model\n",
    "        sentiment_analyzer = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=model_name,\n",
    "            tokenizer=model_name,\n",
    "            return_all_scores=True,  # Get confidence scores\n",
    "            device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "        )\n",
    "        \n",
    "        device_info = 'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'\n",
    "        logger.info(f\"Model loaded successfully! Using device: {device_info}\")\n",
    "        \n",
    "        # Test the model with a sample text\n",
    "        test_result = sentiment_analyzer(\"This is a great product!\")\n",
    "        logger.info(f\"Model test successful: {test_result}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load sentiment model: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Initialize the model\n",
    "success = initialize_sentiment_model()\n",
    "print(f\"Model initialization: {'SUCCESS' if success else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ced4a0",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "498bab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enhanced sentiment analysis with neutral detection ready!\n",
      "Enhanced sentiment analysis with neutral detection ready!\n",
      "Run test_enhanced_analysis() to see the improved results!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced sentiment analysis with neutral detection\n",
    "def analyze_reviews_batch_enhanced(reviews: List[str], neutral_threshold: float = 0.75) -> List[ReviewSentiment]:\n",
    "    \"\"\"\n",
    "    Enhanced sentiment analysis with neutral detection based on confidence threshold\n",
    "    If confidence is below threshold, classify as neutral\n",
    "    \"\"\"\n",
    "    if not sentiment_analyzer:\n",
    "        raise Exception(\"Sentiment model not initialized\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Analyzing {len(reviews)} reviews with neutral detection...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Get predictions for all reviews\n",
    "        predictions = sentiment_analyzer(reviews)\n",
    "        \n",
    "        results = []\n",
    "        for i, (review, prediction) in enumerate(zip(reviews, predictions)):\n",
    "            # Get the highest confidence prediction\n",
    "            best_prediction = max(prediction, key=lambda x: x['score'])\n",
    "            \n",
    "            # Apply neutral threshold logic\n",
    "            if best_prediction['score'] < neutral_threshold:\n",
    "                sentiment = \"Neutral\"  # Low confidence = neutral\n",
    "                confidence = round(1 - best_prediction['score'], 4)  # Invert confidence for neutral\n",
    "            else:\n",
    "                sentiment = map_sentiment_label(best_prediction['label'])\n",
    "                confidence = round(best_prediction['score'], 4)\n",
    "            \n",
    "            results.append(ReviewSentiment(\n",
    "                review=review,\n",
    "                sentiment=sentiment,\n",
    "                confidence=confidence\n",
    "            ))\n",
    "            \n",
    "            logger.debug(f\"Review {i+1}: {sentiment} (confidence: {confidence})\")\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        logger.info(f\"Processing completed in {processing_time:.2f}ms\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during enhanced sentiment analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Test the enhanced version\n",
    "def test_enhanced_analysis():\n",
    "    \"\"\"Test the enhanced analysis with neutral detection\"\"\"\n",
    "    test_reviews_enhanced = [\n",
    "        \"This product is absolutely amazing! Best purchase ever!\",  # Clearly positive\n",
    "        \"Terrible quality, broke after one day. Very disappointed.\",  # Clearly negative  \n",
    "        \"It's okay, nothing special but does the job.\",  # Should be neutral\n",
    "        \"The product works fine.\",  # Should be neutral\n",
    "        \"Not bad, not great, just average.\",  # Should be neutral\n",
    "        \"Love it! Highly recommend to everyone!\",  # Clearly positive\n",
    "        \"Worst product I've ever bought. Complete waste of money.\"  # Clearly negative\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing ENHANCED sentiment analysis...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test with different thresholds\n",
    "    thresholds = [0.75, 0.85, 0.95, 0.99]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nTesting with neutral threshold: {threshold}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            results = analyze_reviews_batch_enhanced(test_reviews_enhanced, threshold)\n",
    "            \n",
    "            # Show results\n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"{i}. {result.sentiment} ({result.confidence:.3f}) - {result.review[:50]}...\")\n",
    "            \n",
    "            # Summary\n",
    "            summary = calculate_summary(results)\n",
    "            print(f\"\\nSummary: Pos:{summary['Positive']}, Neg:{summary['Negative']}, Neu:{summary['Neutral']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error: {str(e)}\")\n",
    "            print(f\"Error: {str(e)}\")\n",
    "print(\" Enhanced sentiment analysis with neutral detection ready!\")\n",
    "print(\"Enhanced sentiment analysis with neutral detection ready!\")\n",
    "print(\"Run test_enhanced_analysis() to see the improved results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ef7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced neutral detection using keyword patterns and sentiment scores\n",
    "def analyze_reviews_batch_smart_neutral(reviews: List[str]) -> List[ReviewSentiment]:\n",
    "    \"\"\"\n",
    "    Smart neutral detection using keyword patterns + confidence analysis\n",
    "    Better approach for detecting truly neutral reviews\n",
    "    \"\"\"\n",
    "    if not sentiment_analyzer:\n",
    "        raise Exception(\"Sentiment model not initialized\")\n",
    "    \n",
    "    # Neutral indicators - words/phrases that suggest neutral sentiment\n",
    "    neutral_keywords = {\n",
    "        # Lukewarm positive\n",
    "        'okay', 'ok', 'fine', 'decent', 'acceptable', 'average', 'alright', 'fair',\n",
    "        # Balanced expressions\n",
    "        'nothing special', 'does the job', 'works as expected', 'as advertised',\n",
    "        'not bad', 'not great', 'could be better', 'could be worse',\n",
    "        # Neutral qualifiers\n",
    "        'standard', 'basic', 'ordinary', 'typical', 'normal', 'regular',\n",
    "        'so-so', 'meh', 'whatever', 'middle of the road'\n",
    "    }\n",
    "    \n",
    "    # Strong sentiment indicators (should override neutral detection)\n",
    "    strong_positive = {'amazing', 'fantastic', 'excellent', 'perfect', 'love', 'best', 'wonderful', 'incredible', 'outstanding'}\n",
    "    strong_negative = {'terrible', 'awful', 'horrible', 'worst', 'hate', 'disgusting', 'useless', 'garbage', 'waste'}\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Analyzing {len(reviews)} reviews with smart neutral detection...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Get predictions for all reviews\n",
    "        predictions = sentiment_analyzer(reviews)\n",
    "        \n",
    "        results = []\n",
    "        for i, (review, prediction) in enumerate(zip(reviews, predictions)):\n",
    "            review_lower = review.lower()\n",
    "            \n",
    "            # Get the highest confidence prediction\n",
    "            best_prediction = max(prediction, key=lambda x: x['score'])\n",
    "            original_sentiment = map_sentiment_label(best_prediction['label'])\n",
    "            original_confidence = round(best_prediction['score'], 4)\n",
    "            \n",
    "            # Check for strong sentiment indicators first\n",
    "            has_strong_positive = any(word in review_lower for word in strong_positive)\n",
    "            has_strong_negative = any(word in review_lower for word in strong_negative)\n",
    "            \n",
    "            # Check for neutral indicators\n",
    "            neutral_score = sum(1 for keyword in neutral_keywords if keyword in review_lower)\n",
    "            \n",
    "            # Decision logic\n",
    "            if has_strong_positive or has_strong_negative:\n",
    "                # Strong sentiment words override neutral detection\n",
    "                sentiment = original_sentiment\n",
    "                confidence = original_confidence\n",
    "            elif neutral_score >= 1:  # Found neutral keywords\n",
    "                # Additional checks for truly neutral reviews\n",
    "                if original_confidence < 0.9 or neutral_score >= 2:\n",
    "                    sentiment = \"Neutral\"\n",
    "                    confidence = round(0.7 + (neutral_score * 0.1), 4)  # Base confidence + keyword bonus\n",
    "                else:\n",
    "                    # High confidence with neutral words - keep original but reduce confidence\n",
    "                    sentiment = original_sentiment\n",
    "                    confidence = round(original_confidence * 0.8, 4)\n",
    "            else:\n",
    "                # No neutral indicators - use original prediction\n",
    "                sentiment = original_sentiment\n",
    "                confidence = original_confidence\n",
    "            \n",
    "            results.append(ReviewSentiment(\n",
    "                review=review,\n",
    "                sentiment=sentiment,\n",
    "                confidence=confidence\n",
    "            ))\n",
    "            \n",
    "            logger.debug(f\"Review {i+1}: {sentiment} ({confidence}) - Neutral keywords: {neutral_score}\")\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        logger.info(f\"Smart processing completed in {processing_time:.2f}ms\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during smart sentiment analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Test the smart neutral detection\n",
    "def test_smart_neutral_analysis():\n",
    "    \"\"\"Test the smart neutral detection approach\"\"\"\n",
    "    test_reviews_smart = [\n",
    "        \"This product is absolutely amazing! Best purchase ever!\",  # Strong positive\n",
    "        \"Terrible quality, broke after one day. Very disappointed.\",  # Strong negative  \n",
    "        \"It's okay, nothing special but does the job.\",  # Neutral (keywords: okay, nothing special, does the job)\n",
    "        \"The product works fine.\",  # Neutral (keyword: fine)\n",
    "        \"Not bad, not great, just average.\",  # Neutral (keywords: not bad, not great, average)\n",
    "        \"Love it! Highly recommend to everyone!\",  # Strong positive\n",
    "        \"Worst product I've ever bought. Complete waste of money.\",  # Strong negative\n",
    "        \"Decent quality for the price, nothing extraordinary.\",  # Neutral (keywords: decent, nothing)\n",
    "        \"Works as advertised, pretty standard stuff.\",  # Neutral (keywords: as advertised, standard)\n",
    "        \"Meh, it's alright I guess.\",  # Neutral (keywords: meh, alright)\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing SMART neutral detection approach...\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    try:\n",
    "        results = analyze_reviews_batch_smart_neutral(test_reviews_smart)\n",
    "        \n",
    "        # Show results with more detail\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"{i:2d}. {result.sentiment:8s} ({result.confidence:.3f}) - {result.review}\")\n",
    "        \n",
    "        # Summary\n",
    "        summary = calculate_summary(results)\n",
    "        print(f\"\\nSummary: Positive: {summary['Positive']}, Negative: {summary['Negative']}, Neutral: {summary['Neutral']}\")\n",
    "        print(f\"Total: {sum(summary.values())} reviews\")\n",
    "        \n",
    "        # Show improvement\n",
    "        neutral_percentage = (summary['Neutral'] / sum(summary.values())) * 100\n",
    "        print(f\"Neutral detection rate: {neutral_percentage:.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "print(\"Smart neutral detection with keyword analysis ready!\")\n",
    "print(\"Run test_smart_neutral_analysis() to see much better neutral detection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acf6372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Smart Neutral Detection\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_smart_neutral_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Run the smart test\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtest_smart_neutral_analysis\u001b[49m()\n",
      "\u001b[31mNameError\u001b[39m: name 'test_smart_neutral_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the smart neutral detection\n",
    "print(\"Testing Smart Neutral Detection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run the smart test\n",
    "test_smart_neutral_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "105a5a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 21:00:51,540 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Enhanced Sentiment Analysis with Neutral Detection\n",
      "======================================================================\n",
      "Testing ENHANCED sentiment analysis...\n",
      "============================================================\n",
      "\n",
      "Testing with neutral threshold: 0.75\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 21:00:52,424 - __main__ - INFO - Processing completed in 883.48ms\n",
      "2025-09-27 21:00:52,426 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n",
      "2025-09-27 21:00:52,426 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n",
      "2025-09-27 21:00:52,611 - __main__ - INFO - Processing completed in 184.38ms\n",
      "2025-09-27 21:00:52,612 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n",
      "2025-09-27 21:00:52,611 - __main__ - INFO - Processing completed in 184.38ms\n",
      "2025-09-27 21:00:52,612 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positive (1.000) - This product is absolutely amazing! Best purchase ...\n",
      "2. Negative (1.000) - Terrible quality, broke after one day. Very disapp...\n",
      "3. Positive (1.000) - It's okay, nothing special but does the job....\n",
      "4. Positive (1.000) - The product works fine....\n",
      "5. Negative (0.895) - Not bad, not great, just average....\n",
      "6. Positive (1.000) - Love it! Highly recommend to everyone!...\n",
      "7. Negative (1.000) - Worst product I've ever bought. Complete waste of ...\n",
      "\n",
      "Summary: Pos:4, Neg:3, Neu:0\n",
      "\n",
      "Testing with neutral threshold: 0.85\n",
      "----------------------------------------\n",
      "1. Positive (1.000) - This product is absolutely amazing! Best purchase ...\n",
      "2. Negative (1.000) - Terrible quality, broke after one day. Very disapp...\n",
      "3. Positive (1.000) - It's okay, nothing special but does the job....\n",
      "4. Positive (1.000) - The product works fine....\n",
      "5. Negative (0.895) - Not bad, not great, just average....\n",
      "6. Positive (1.000) - Love it! Highly recommend to everyone!...\n",
      "7. Negative (1.000) - Worst product I've ever bought. Complete waste of ...\n",
      "\n",
      "Summary: Pos:4, Neg:3, Neu:0\n",
      "\n",
      "Testing with neutral threshold: 0.95\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 21:00:52,700 - __main__ - INFO - Processing completed in 87.14ms\n",
      "2025-09-27 21:00:52,701 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n",
      "2025-09-27 21:00:52,701 - __main__ - INFO - Analyzing 7 reviews with neutral detection...\n",
      "2025-09-27 21:00:52,793 - __main__ - INFO - Processing completed in 89.88ms\n",
      "2025-09-27 21:00:52,793 - __main__ - INFO - Processing completed in 89.88ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positive (1.000) - This product is absolutely amazing! Best purchase ...\n",
      "2. Negative (1.000) - Terrible quality, broke after one day. Very disapp...\n",
      "3. Positive (1.000) - It's okay, nothing special but does the job....\n",
      "4. Positive (1.000) - The product works fine....\n",
      "5. Neutral (0.105) - Not bad, not great, just average....\n",
      "6. Positive (1.000) - Love it! Highly recommend to everyone!...\n",
      "7. Negative (1.000) - Worst product I've ever bought. Complete waste of ...\n",
      "\n",
      "Summary: Pos:4, Neg:2, Neu:1\n",
      "\n",
      "Testing with neutral threshold: 0.99\n",
      "----------------------------------------\n",
      "1. Positive (1.000) - This product is absolutely amazing! Best purchase ...\n",
      "2. Negative (1.000) - Terrible quality, broke after one day. Very disapp...\n",
      "3. Positive (1.000) - It's okay, nothing special but does the job....\n",
      "4. Positive (1.000) - The product works fine....\n",
      "5. Neutral (0.105) - Not bad, not great, just average....\n",
      "6. Positive (1.000) - Love it! Highly recommend to everyone!...\n",
      "7. Negative (1.000) - Worst product I've ever bought. Complete waste of ...\n",
      "\n",
      "Summary: Pos:4, Neg:2, Neu:1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the enhanced neutral detection\n",
    "print(\"Testing Enhanced Sentiment Analysis with Neutral Detection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run the enhanced test\n",
    "test_enhanced_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "960133f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def map_sentiment_label(label: str) -> str:\n",
    "    \"\"\"\n",
    "    Map model output labels to standardized sentiment labels\n",
    "    DistilBERT SST-2 outputs: POSITIVE, NEGATIVE\n",
    "    We map to: Positive, Negative, Neutral (though SST-2 doesn't have neutral)\n",
    "    \"\"\"\n",
    "    label_mapping = {\n",
    "        \"POSITIVE\": \"Positive\",\n",
    "        \"NEGATIVE\": \"Negative\",\n",
    "        \"NEUTRAL\": \"Neutral\"  # For future models that support neutral\n",
    "    }\n",
    "    return label_mapping.get(label.upper(), label)\n",
    "\n",
    "def analyze_reviews_batch(reviews: List[str]) -> List[ReviewSentiment]:\n",
    "    \"\"\"\n",
    "    Analyze sentiment for a batch of reviews\n",
    "    Returns structured results with confidence scores\n",
    "    \"\"\"\n",
    "    if not sentiment_analyzer:\n",
    "        raise Exception(\"Sentiment model not initialized\")\n",
    "    \n",
    "    try:\n",
    "        # Process all reviews in batch for efficiency\n",
    "        logger.info(f\"Analyzing {len(reviews)} reviews...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Get predictions for all reviews\n",
    "        predictions = sentiment_analyzer(reviews)\n",
    "        \n",
    "        results = []\n",
    "        for i, (review, prediction) in enumerate(zip(reviews, predictions)):\n",
    "            # Get the highest confidence prediction\n",
    "            best_prediction = max(prediction, key=lambda x: x['score'])\n",
    "            \n",
    "            sentiment = map_sentiment_label(best_prediction['label'])\n",
    "            confidence = round(best_prediction['score'], 4)\n",
    "            \n",
    "            results.append(ReviewSentiment(\n",
    "                review=review,\n",
    "                sentiment=sentiment,\n",
    "                confidence=confidence\n",
    "            ))\n",
    "            \n",
    "            logger.debug(f\"Review {i+1}: {sentiment} (confidence: {confidence})\")\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        logger.info(f\"Processing completed in {processing_time:.2f}ms\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during sentiment analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def calculate_summary(results: List[ReviewSentiment]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Calculate aggregate counts of sentiment labels\n",
    "    \"\"\"\n",
    "    summary = {\"Positive\": 0, \"Negative\": 0, \"Neutral\": 0}\n",
    "    \n",
    "    for result in results:\n",
    "        if result.sentiment in summary:\n",
    "            summary[result.sentiment] += 1\n",
    "    \n",
    "    return summary\n",
    "\n",
    "print(\"Helper functions defined successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
