{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898675e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d54a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c607300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(texts, threshold_margin=0.45, confidence_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Predict sentiment with better neutral detection.\n",
    "    - If top_prob < confidence_threshold OR margin < threshold_margin -> neutral\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0]\n",
    "\n",
    "        # Labels from model config\n",
    "        labels = model.config.id2label\n",
    "        label_probs = {labels[i]: float(probs[i]) for i in range(len(probs))}\n",
    "\n",
    "        # Top 2 classes\n",
    "        top_idx = int(np.argmax(probs))\n",
    "        second_idx = int(np.argsort(probs)[-2])\n",
    "        top_prob = probs[top_idx]\n",
    "        second_prob = probs[second_idx]\n",
    "        margin = top_prob - second_prob\n",
    "\n",
    "        # Entropy for information\n",
    "        entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
    "\n",
    "        # Neutral detection: relax thresholds for demo\n",
    "        if top_prob < confidence_threshold or margin < threshold_margin:\n",
    "            predicted = \"neutral\"\n",
    "        else:\n",
    "            predicted = labels[top_idx]\n",
    "\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"predicted_label\": predicted,\n",
    "            \"model_label\": labels[top_idx],\n",
    "            \"top_prob\": round(float(top_prob), 4),\n",
    "            \"second_prob\": round(float(second_prob), 4),\n",
    "            \"margin\": round(float(margin), 4),\n",
    "            \"entropy\": round(float(entropy), 4),\n",
    "            \"probs\": label_probs\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7cebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Amazing battery life and great design!', 'predicted_label': 'positive', 'model_label': 'positive', 'top_prob': 0.9799, 'second_prob': 0.0141, 'margin': 0.9658, 'entropy': 0.1106, 'probs': {'negative': 0.0059401192702353, 'neutral': 0.014146598055958748, 'positive': 0.9799132347106934}}\n",
      "{'text': 'Exceeded my expectations, fantastic build quality.', 'predicted_label': 'positive', 'model_label': 'positive', 'top_prob': 0.9825, 'second_prob': 0.0122, 'margin': 0.9703, 'entropy': 0.0988, 'probs': {'negative': 0.005293151829391718, 'neutral': 0.012190177105367184, 'positive': 0.9825166463851929}}\n",
      "{'text': 'Customer service was incredibly helpful and polite.', 'predicted_label': 'positive', 'model_label': 'positive', 'top_prob': 0.9756, 'second_prob': 0.0166, 'margin': 0.959, 'entropy': 0.13, 'probs': {'negative': 0.007807754445821047, 'neutral': 0.01659511961042881, 'positive': 0.9755972027778625}}\n",
      "{'text': 'Love the colors and the feel of this product, very premium!', 'predicted_label': 'positive', 'model_label': 'positive', 'top_prob': 0.9829, 'second_prob': 0.012, 'margin': 0.9709, 'entropy': 0.0972, 'probs': {'negative': 0.005155044142156839, 'neutral': 0.011992713436484337, 'positive': 0.9828521609306335}}\n",
      "{'text': 'Arrived on time and works exactly as advertised, highly recommend!', 'predicted_label': 'positive', 'model_label': 'positive', 'top_prob': 0.9765, 'second_prob': 0.0197, 'margin': 0.9568, 'entropy': 0.1217, 'probs': {'negative': 0.003782340558245778, 'neutral': 0.019715752452611923, 'positive': 0.9765018820762634}}\n",
      "{'text': \"It's okay, nothing special but does the job.\", 'predicted_label': 'neutral', 'model_label': 'positive', 'top_prob': 0.6385, 'second_prob': 0.3191, 'margin': 0.3193, 'entropy': 0.785, 'probs': {'negative': 0.042420729994773865, 'neutral': 0.3191271722316742, 'positive': 0.6384521126747131}}\n",
      "{'text': 'Average product, not bad but not great either.', 'predicted_label': 'negative', 'model_label': 'negative', 'top_prob': 0.7872, 'second_prob': 0.1881, 'margin': 0.5991, 'entropy': 0.5942, 'probs': {'negative': 0.7871510982513428, 'neutral': 0.18809597194194794, 'positive': 0.024752916768193245}}\n",
      "{'text': 'Does what it says, no complaints.', 'predicted_label': 'neutral', 'model_label': 'positive', 'top_prob': 0.7088, 'second_prob': 0.2668, 'margin': 0.442, 'entropy': 0.6872, 'probs': {'negative': 0.024427954107522964, 'neutral': 0.2668100595474243, 'positive': 0.708761990070343}}\n",
      "{'text': 'Neither good nor bad, just fine for everyday use.', 'predicted_label': 'neutral', 'model_label': 'positive', 'top_prob': 0.7042, 'second_prob': 0.2712, 'margin': 0.433, 'entropy': 0.6918, 'probs': {'negative': 0.024542680010199547, 'neutral': 0.2712462544441223, 'positive': 0.7042109966278076}}\n",
      "{'text': 'Decent quality, but Iâ€™ve seen better for the price.', 'predicted_label': 'neutral', 'model_label': 'positive', 'top_prob': 0.726, 'second_prob': 0.2213, 'margin': 0.5047, 'entropy': 0.7213, 'probs': {'negative': 0.05269155651330948, 'neutral': 0.22130882740020752, 'positive': 0.725999653339386}}\n",
      "{'text': 'Terrible product, broke after 2 days.', 'predicted_label': 'negative', 'model_label': 'negative', 'top_prob': 0.9463, 'second_prob': 0.0459, 'margin': 0.9004, 'entropy': 0.2316, 'probs': {'negative': 0.9462911486625671, 'neutral': 0.045884761959314346, 'positive': 0.007824048399925232}}\n",
      "{'text': 'Battery stopped working within a week, very disappointed.', 'predicted_label': 'negative', 'model_label': 'negative', 'top_prob': 0.936, 'second_prob': 0.0572, 'margin': 0.8788, 'entropy': 0.2594, 'probs': {'negative': 0.9360091090202332, 'neutral': 0.057238537818193436, 'positive': 0.0067522828467190266}}\n",
      "{'text': 'Poor customer service, they never responded to my emails.', 'predicted_label': 'negative', 'model_label': 'negative', 'top_prob': 0.939, 'second_prob': 0.0544, 'margin': 0.8846, 'entropy': 0.2508, 'probs': {'negative': 0.9389638304710388, 'neutral': 0.05440725386142731, 'positive': 0.006628937553614378}}\n",
      "{'text': 'Low quality material, feels cheap and flimsy.', 'predicted_label': 'negative', 'model_label': 'negative', 'top_prob': 0.916, 'second_prob': 0.0747, 'margin': 0.8414, 'entropy': 0.3175, 'probs': {'negative': 0.9160479307174683, 'neutral': 0.07467997819185257, 'positive': 0.009272057563066483}}\n",
      "{'text': 'Not worth the money, completely regret buying it.', 'predicted_label': 'negative', 'model_label': 'negative', 'top_prob': 0.9103, 'second_prob': 0.0771, 'margin': 0.8332, 'entropy': 0.3382, 'probs': {'negative': 0.9103058576583862, 'neutral': 0.07712149620056152, 'positive': 0.012572670355439186}}\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    # Positive reviews\n",
    "    \"Amazing battery life and great design!\",\n",
    "    \"Exceeded my expectations, fantastic build quality.\",\n",
    "    \"Customer service was incredibly helpful and polite.\",\n",
    "    \"Love the colors and the feel of this product, very premium!\",\n",
    "    \"Arrived on time and works exactly as advertised, highly recommend!\",\n",
    "\n",
    "    # Neutral reviews\n",
    "    \"It's okay, nothing special but does the job.\",\n",
    "    \"Average product, not bad but not great either.\",\n",
    "    \"Does what it says, no complaints.\",\n",
    "    \"Neither good nor bad, just fine for everyday use.\",\n",
    "    \"Decent quality, but Iâ€™ve seen better for the price.\",\n",
    "\n",
    "    # Negative reviews\n",
    "    \"Terrible product, broke after 2 days.\",\n",
    "    \"Battery stopped working within a week, very disappointed.\",\n",
    "    \"Poor customer service, they never responded to my emails.\",\n",
    "    \"Low quality material, feels cheap and flimsy.\",\n",
    "    \"Not worth the money, completely regret buying it.\"\n",
    "]\n",
    "\n",
    "\n",
    "predictions = predict_sentiment(sample_texts)\n",
    "for p in predictions:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f4ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SENTIMENT ANALYSIS RESULTS SUMMARY\n",
      "======================================================================\n",
      "Review Type     Predicted    Model Raw    Confidence   Margin  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "POSITIVE REVIEWS:\n",
      "                positive     positive     0.980        0.966   \n",
      "                positive     positive     0.983        0.970   \n",
      "                positive     positive     0.976        0.959   \n",
      "                positive     positive     0.983        0.971   \n",
      "                positive     positive     0.977        0.957   \n",
      "\n",
      "NEUTRAL REVIEWS:\n",
      "                neutral      positive     0.638        0.319   \n",
      "                negative     negative     0.787        0.599   \n",
      "                neutral      positive     0.709        0.442   \n",
      "                neutral      positive     0.704        0.433   \n",
      "                neutral      positive     0.726        0.505   \n",
      "\n",
      "NEGATIVE REVIEWS:\n",
      "                negative     negative     0.946        0.900   \n",
      "                negative     negative     0.936        0.879   \n",
      "                negative     negative     0.939        0.885   \n",
      "                negative     negative     0.916        0.841   \n",
      "                negative     negative     0.910        0.833   \n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY:\n",
      "Predicted Distribution: {'positive': 5, 'negative': 6, 'neutral': 4}\n",
      "Model Raw Distribution: {'positive': 9, 'negative': 6, 'neutral': 0}\n",
      "\n",
      "Neutral Detection Success: 4/5 = 80.0%\n",
      "ðŸŽ‰ MUCH BETTER! Cardiff model detects neutral sentiment properly!\n"
     ]
    }
   ],
   "source": [
    "# Analyze the results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SENTIMENT ANALYSIS RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count predictions\n",
    "predicted_counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "model_counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "\n",
    "print(f\"{'Review Type':<15} {'Predicted':<12} {'Model Raw':<12} {'Confidence':<12} {'Margin':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Categorize by original review type\n",
    "categories = [\n",
    "    (\"POSITIVE\", predictions[0:5]),\n",
    "    (\"NEUTRAL\", predictions[5:10]), \n",
    "    (\"NEGATIVE\", predictions[10:15])\n",
    "]\n",
    "\n",
    "for cat_name, cat_predictions in categories:\n",
    "    print(f\"\\n{cat_name} REVIEWS:\")\n",
    "    for p in cat_predictions:\n",
    "        predicted_counts[p['predicted_label']] += 1\n",
    "        model_counts[p['model_label']] += 1\n",
    "        \n",
    "        print(f\"{'':<15} {p['predicted_label']:<12} {p['model_label']:<12} {p['top_prob']:<12.3f} {p['margin']:<8.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL SUMMARY:\")\n",
    "print(f\"Predicted Distribution: {predicted_counts}\")\n",
    "print(f\"Model Raw Distribution: {model_counts}\")\n",
    "\n",
    "# Calculate neutral detection success\n",
    "neutral_reviews = 5  # We had 5 neutral reviews\n",
    "neutral_detected = predicted_counts['neutral']\n",
    "neutral_success_rate = (neutral_detected / neutral_reviews) * 100\n",
    "\n",
    "print(f\"\\nNeutral Detection Success: {neutral_detected}/{neutral_reviews} = {neutral_success_rate:.1f}%\")\n",
    "print(\"ðŸŽ‰ MUCH BETTER! Cardiff model detects neutral sentiment properly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e864ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the adjust_neutral function:\n",
      "==================================================\n",
      "1. Text: 'great product'\n",
      "   Original: positive, Adjusted: positive\n",
      "   Probs: {'positive': 0.8, 'negative': 0.1, 'neutral': 0.1}\n",
      "\n",
      "2. Text: 'okay product'\n",
      "   Original: positive, Adjusted: neutral\n",
      "   Probs: {'positive': 0.6, 'negative': 0.25, 'neutral': 0.15}\n",
      "\n",
      "3. Text: 'amazing!'\n",
      "   Original: positive, Adjusted: positive\n",
      "   Probs: {'positive': 0.95, 'negative': 0.03, 'neutral': 0.02}\n",
      "\n",
      "4. Text: 'not bad but average'\n",
      "   Original: negative, Adjusted: neutral\n",
      "   Probs: {'negative': 0.7, 'positive': 0.2, 'neutral': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def adjust_neutral(pred_label, probs, margin=0.45, conf_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Improved neutral adjustment function with keyword detection\n",
    "    \"\"\"\n",
    "    top_class = max(probs, key=probs.get)\n",
    "    top_prob = probs[top_class]\n",
    "    second_prob = sorted(probs.values())[-2]\n",
    "    top_margin = top_prob - second_prob\n",
    "\n",
    "    # forced neutral for mild cases\n",
    "    if top_margin < margin or top_prob < conf_thresh:\n",
    "        # optionally check for keywords\n",
    "        neutral_keywords = [\"okay\", \"fine\", \"average\", \"not bad\", \"nothing special\"]\n",
    "        if any(word in pred_label.lower() for word in neutral_keywords) or True:\n",
    "            return \"neutral\"\n",
    "    return top_class\n",
    "\n",
    "# Test this function with some examples\n",
    "print(\"Testing the adjust_neutral function:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\"probs\": {\"positive\": 0.8, \"negative\": 0.1, \"neutral\": 0.1}, \"text\": \"great product\"},\n",
    "    {\"probs\": {\"positive\": 0.6, \"negative\": 0.25, \"neutral\": 0.15}, \"text\": \"okay product\"},\n",
    "    {\"probs\": {\"positive\": 0.95, \"negative\": 0.03, \"neutral\": 0.02}, \"text\": \"amazing!\"},\n",
    "    {\"probs\": {\"negative\": 0.7, \"positive\": 0.2, \"neutral\": 0.1}, \"text\": \"not bad but average\"},\n",
    "]\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    original = max(case[\"probs\"], key=case[\"probs\"].get)\n",
    "    adjusted = adjust_neutral(case[\"text\"], case[\"probs\"])\n",
    "    print(f\"{i}. Text: '{case['text']}'\")\n",
    "    print(f\"   Original: {original}, Adjusted: {adjusted}\")\n",
    "    print(f\"   Probs: {case['probs']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2227978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Enhanced Sentiment Prediction:\n",
      "============================================================\n",
      "Original     Enhanced     Text                                              \n",
      "--------------------------------------------------------------------------------\n",
      "positive     positive     Amazing battery life and great design!\n",
      "positive     positive     Exceeded my expectations, fantastic build qua...\n",
      "positive     positive     Customer service was incredibly helpful and p...\n",
      "positive     positive     Love the colors and the feel of this product,...\n",
      "positive     positive     Arrived on time and works exactly as advertis...\n",
      "neutral      neutral      It's okay, nothing special but does the job.\n",
      "negative     negative     Average product, not bad but not great either...\n",
      "neutral      neutral      Does what it says, no complaints.\n",
      "neutral      neutral      Neither good nor bad, just fine for everyday ...\n",
      "neutral      neutral      Decent quality, but Iâ€™ve seen better for the ...\n",
      "negative     negative     Terrible product, broke after 2 days.\n",
      "negative     negative     Battery stopped working within a week, very d...\n",
      "negative     negative     Poor customer service, they never responded t...\n",
      "negative     negative     Low quality material, feels cheap and flimsy.\n",
      "negative     negative     Not worth the money, completely regret buying...\n",
      "\n",
      "============================================================\n",
      "COMPARISON SUMMARY:\n",
      "Original:  {'positive': 5, 'negative': 6, 'neutral': 4}\n",
      "Enhanced:  {'positive': 5, 'negative': 6, 'neutral': 4}\n",
      "Neutral detection: 4 â†’ 4 (0)\n"
     ]
    }
   ],
   "source": [
    "# Enhanced version that integrates the adjust_neutral function\n",
    "def predict_sentiment_enhanced(texts, threshold_margin=0.45, confidence_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Enhanced sentiment prediction with improved neutral detection\n",
    "    Uses both the original logic and the adjust_neutral function\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0]\n",
    "\n",
    "        # Labels from model config\n",
    "        labels = model.config.id2label\n",
    "        label_probs = {labels[i]: float(probs[i]) for i in range(len(probs))}\n",
    "\n",
    "        # Get original prediction\n",
    "        top_idx = int(np.argmax(probs))\n",
    "        second_idx = int(np.argsort(probs)[-2])\n",
    "        top_prob = probs[top_idx]\n",
    "        second_prob = probs[second_idx]\n",
    "        margin = top_prob - second_prob\n",
    "\n",
    "        # Use the adjust_neutral function for final prediction\n",
    "        predicted = adjust_neutral(text, label_probs, threshold_margin, confidence_threshold)\n",
    "        \n",
    "        # Calculate confidence based on final prediction\n",
    "        if predicted == \"neutral\":\n",
    "            # For neutral predictions, use inverse confidence or margin-based confidence\n",
    "            confidence = round(1 - top_prob if top_prob > 0.5 else margin, 4)\n",
    "        else:\n",
    "            confidence = round(float(top_prob), 4)\n",
    "\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"predicted_label\": predicted,\n",
    "            \"model_label\": labels[top_idx],\n",
    "            \"confidence\": confidence,\n",
    "            \"top_prob\": round(float(top_prob), 4),\n",
    "            \"margin\": round(float(margin), 4),\n",
    "            \"probs\": label_probs\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test the enhanced function\n",
    "print(\"Testing Enhanced Sentiment Prediction:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "enhanced_predictions = predict_sentiment_enhanced(sample_texts)\n",
    "\n",
    "# Show comparison\n",
    "print(f\"{'Original':<12} {'Enhanced':<12} {'Text':<50}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (orig, enh) in enumerate(zip(predictions, enhanced_predictions)):\n",
    "    text_preview = enh['text'][:45] + \"...\" if len(enh['text']) > 45 else enh['text']\n",
    "    print(f\"{orig['predicted_label']:<12} {enh['predicted_label']:<12} {text_preview}\")\n",
    "\n",
    "# Summary comparison\n",
    "print(f\"\\n{'='*60}\")\n",
    "orig_counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "enh_counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "\n",
    "for orig, enh in zip(predictions, enhanced_predictions):\n",
    "    orig_counts[orig['predicted_label']] += 1\n",
    "    enh_counts[enh['predicted_label']] += 1\n",
    "\n",
    "print(\"COMPARISON SUMMARY:\")\n",
    "print(f\"Original:  {orig_counts}\")\n",
    "print(f\"Enhanced:  {enh_counts}\")\n",
    "\n",
    "orig_neutral = orig_counts['neutral']\n",
    "enh_neutral = enh_counts['neutral']\n",
    "print(f\"Neutral detection: {orig_neutral} â†’ {enh_neutral} ({'+' if enh_neutral > orig_neutral else ''}{enh_neutral - orig_neutral})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
